Great! Since you've successfully mapped the port and verified internal access, let's create a practical exercise for using YARN (Yet Another Resource Negotiator) in a Hadoop environment. We'll walk through a basic YARN job that will utilize the ResourceManager for job submission.

### Practical: Running a WordCount Job on YARN

In this practical, we will run a simple word count job using Hadoop YARN. This exercise will guide you through preparing a basic Hadoop job and running it on a YARN cluster.

### Prerequisites:
1. **YARN ResourceManager** and **NodeManager** must be up and running (which they are now).
2. You should have a Hadoop job (e.g., WordCount) ready to be executed.
3. HDFS should be running, and you should have access to the HDFS file system for input and output.

### Step-by-Step Guide

#### Step 1: Upload Data to HDFS

Before you can run a YARN job, you need to upload some input data to HDFS. We will create a text file on your local machine and upload it to HDFS.

1. **Create a sample text file locally**:
   Create a file `sample.txt` on your local machine with some sample text data. You can use any text editor or use the `echo` command to quickly create one.

   ```bash
   echo "Hadoop YARN Resource Manager" > sample.txt
   echo "YARN is responsible for managing resources" >> sample.txt
   echo "It is a resource manager and job scheduler" >> sample.txt
   ```

2. **Upload the text file to HDFS**:
   Use the `hadoop fs -put` command to upload the file to HDFS.

   ```bash
   hadoop fs -mkdir -p /user/root/input  # Create input directory in HDFS
   hadoop fs -put sample.txt /user/root/input/
   ```

   You can check if the file has been uploaded successfully by running:

   ```bash
   hadoop fs -ls /user/root/input/
   ```

#### Step 2: Submit the WordCount Job to YARN

Now that we have a sample file in HDFS, we can run a MapReduce job (WordCount) using YARN.

1. **Run the WordCount job on YARN**:
   The Hadoop job will process the input file using the YARN ResourceManager. Use the following command:

   ```bash
   hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar \
   wordcount /user/root/input/sample.txt /user/root/output
   ```

   - `wordcount`: The name of the MapReduce program.
   - `/user/root/input/sample.txt`: The input file on HDFS.
   - `/user/root/output`: The directory on HDFS where the output will be stored.

2. **Check the YARN UI**:
   The job will be submitted to the YARN ResourceManager, and you can monitor its progress through the YARN ResourceManager UI.

   Go to `http://localhost:8088` (or `http://<container-ip>:8088` if using a different IP) and look for your job in the "Applications" section.

3. **Monitor the Job**:
   Once the job is submitted, you can see its status and logs in the YARN ResourceManager UI. You can track:
   - Job progress
   - Running containers
   - Job execution logs

#### Step 3: Check the Output of the WordCount Job

Once the job has completed successfully, you can view the results of the WordCount job stored in the output directory in HDFS.

1. **Check output on HDFS**:

   ```bash
   hadoop fs -ls /user/root/output
   ```

   You should see files like `part-r-00000` generated by the job.

2. **View the contents of the output file**:

   To view the word count output, you can use the `cat` command:

   ```bash
   hadoop fs -cat /user/root/output/part-r-00000
   ```

   The output will show the words in the input file along with their counts, like this:

   ```
   Hadoop 1
   YARN 2
   Resource 1
   Manager 1
   is 1
   responsible 1
   for 1
   managing 1
   resources 1
   and 1
   job 1
   scheduler 1
   ```

#### Step 4: Clean Up

After you have completed the practical, it's good practice to clean up by deleting the output directory and any intermediate files:

1. **Remove the output directory from HDFS**:

   ```bash
   hadoop fs -rm -r /user/root/output
   ```

2. **Optional**: You can also remove the input file from HDFS if you no longer need it.

   ```bash
   hadoop fs -rm /user/root/input/sample.txt
   ```

### Additional Tips

- You can try running different MapReduce jobs and monitor their progress using the YARN UI.
- If you want to run custom jobs, you can write your own MapReduce program in Java and package it into a JAR file, then submit it to YARN in a similar manner.

---

### Troubleshooting

- **Job not starting**: If the job doesn't start or fails to run, check the logs in the YARN UI or using the command `yarn logs -applicationId <app-id>` to view the detailed logs.
- **Out of memory errors**: If your job runs into memory-related issues, consider adjusting the memory allocation for YARN containers in the `yarn-site.xml` configuration file.

This practical gives you a basic understanding of how to submit jobs to YARN and monitor them. You can build on this by experimenting with other Hadoop tools and configurations.
